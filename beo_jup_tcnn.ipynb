{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousseau/miniconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/rousseau/miniconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import tinycudann as tcnn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMLP(pl.LightningModule):\n",
    "  def __init__(self, config, dim_in=3, dim_out=1):\n",
    "    super().__init__()\n",
    "    self.dim_in = dim_in\n",
    "    self.dim_out = dim_out\n",
    "\n",
    "    self.encoding = tcnn.Encoding(n_input_dims=dim_in, encoding_config=config['encoding'])\n",
    "    self.mlp= tcnn.Network(n_input_dims=self.encoding.n_output_dims, n_output_dims=dim_out, network_config=config['network'])\n",
    "    self.model = torch.nn.Sequential(self.encoding, self.mlp)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=5e-3)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    z = self(x)\n",
    "\n",
    "    loss = F.mse_loss(z, y)\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def predict_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousseau/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "batch_size = 4096*4\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "#Read image\n",
    "image_file = '/home/rousseau/Sync-Exp/Data/template_dHCP/fetal_brain_mri_atlas/structural/t1-t21.00.nii.gz'\n",
    "image = nib.load(image_file)\n",
    "data = image.get_fdata()\n",
    "\n",
    "#Create grid\n",
    "dim = 3\n",
    "x = torch.linspace(-1, 1, steps=data.shape[0])\n",
    "y = torch.linspace(-1, 1, steps=data.shape[1])\n",
    "z = torch.linspace(-1, 1, steps=data.shape[2])\n",
    "\n",
    "mgrid = torch.stack(torch.meshgrid(x,y,z), dim=-1)\n",
    "\n",
    "#Convert to X=(x,y,z) and Y=intensity\n",
    "X = torch.Tensor(mgrid.reshape(-1,dim))\n",
    "Y = torch.Tensor(data.flatten())\n",
    "\n",
    "#Normalize intensities between [-1,1]\n",
    "Y = (Y - torch.min(Y)) / (torch.max(Y) - torch.min(Y)) * 2 - 1\n",
    "Y = torch.reshape(Y, (-1,1))\n",
    "\n",
    "#Pytorch dataloader\n",
    "dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#https://github.com/NVlabs/tiny-cuda-nn/blob/master/DOCUMENTATION.md\n",
    "config = {\n",
    "\"encoding\": {\n",
    "    \"otype\": \"HashGrid\",\n",
    "    \"n_levels\": 8,\n",
    "    \"n_features_per_level\": 2,\n",
    "    \"log2_hashmap_size\": 15,\n",
    "    \"base_resolution\": 16,\n",
    "    \"per_level_scale\": 1.3819#1.5\n",
    "},\n",
    "\"network\": {\n",
    "    \"otype\": \"FullyFusedMLP\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"output_activation\": \"None\",\n",
    "    \"n_neurons\": 128,\n",
    "    \"n_hidden_layers\": 2\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rousseau/miniconda3/lib/python3.10/site-packages/lightning_fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/rousseau/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoding | Encoding   | 419 K \n",
      "1 | mlp      | Network    | 20.5 K\n",
      "2 | model    | Sequential | 440 K \n",
      "----------------------------------------\n",
      "440 K     Trainable params\n",
      "0         Non-trainable params\n",
      "440 K     Total params\n",
      "1.761     Total estimated model params size (MB)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rousseau/miniconda3/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/rousseau/miniconda3/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/rousseau/miniconda3/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/rousseau/miniconda3/lib/python3.10/shutil.py\", line 731, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/home/rousseau/miniconda3/lib/python3.10/shutil.py\", line 729, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-rm7esbn1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5b0693a8d24884a8665d8b8faff3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    }
   ],
   "source": [
    "net = HashMLP(config = config, dim_in=3, dim_out=1)\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, precision=16)\n",
    "trainer.fit(net, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7160400, 3])\n",
      "torch.Size([7160400, 16])\n",
      "torch.Size([180, 221, 180, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X = X.to(device='cuda')\n",
    "net = net.to(device='cuda')\n",
    "enc = net.encoding(X)\n",
    "print(enc.shape)\n",
    "print(mgrid.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
