{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import tinycudann as tcnn\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashMLP(pl.LightningModule):\n",
    "  def __init__(self, config, dim_in=3, dim_out=1):\n",
    "    super().__init__()\n",
    "    self.dim_in = dim_in\n",
    "    self.dim_out = dim_out\n",
    "\n",
    "    self.encoding = tcnn.Encoding(n_input_dims=dim_in, encoding_config=config['encoding'])\n",
    "    self.mlp= tcnn.Network(n_input_dims=self.encoding.n_output_dims, n_output_dims=dim_out, network_config=config['network'])\n",
    "    self.model = torch.nn.Sequential(self.encoding, self.mlp)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=5e-3)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    z = self(x)\n",
    "\n",
    "    loss = F.mse_loss(z, y)\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def predict_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096*4\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "#Read image\n",
    "image_file = os.path.join(home,'Sync-Exp','dhcp128.nii.gz')\n",
    "\n",
    "image = nib.load(image_file)\n",
    "data = image.get_fdata()\n",
    "\n",
    "#Create grid\n",
    "dim = 3\n",
    "# BUG\n",
    "#x = torch.linspace(-1, 1, steps=data.shape[0])\n",
    "#y = torch.linspace(-1, 1, steps=data.shape[1])\n",
    "#z = torch.linspace(-1, 1, steps=data.shape[2])\n",
    "# Needs positive coordinates !\n",
    "x = torch.linspace(0, 1, steps=data.shape[0])\n",
    "y = torch.linspace(0, 1, steps=data.shape[1])\n",
    "z = torch.linspace(0, 1, steps=data.shape[2])\n",
    "\n",
    "#Convert to X=(x,y,z) and Y=intensity\n",
    "mgrid = torch.stack(torch.meshgrid(x,y,z,indexing='ij'), dim=-1)\n",
    "X = torch.Tensor(mgrid.reshape(-1,dim))\n",
    "Y = torch.Tensor(data.flatten())\n",
    "\n",
    "#Normalize intensities between [-1,1]\n",
    "Y = (Y - torch.min(Y)) / (torch.max(Y) - torch.min(Y)) * 2 - 1\n",
    "Y = torch.reshape(Y, (-1,1))\n",
    "\n",
    "#Pytorch dataloader\n",
    "dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgrid.shape\n",
    "print(X[0:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx = data.shape[0]\n",
    "ny = data.shape[1]\n",
    "nz = data.shape[2]\n",
    "nmax = np.max([nx,ny,nz])\n",
    "\n",
    "'''\n",
    "# Manual building of the grid of coordinates\n",
    "half_dx = 0.5 / nx\n",
    "half_dy = 0.5 / ny\n",
    "half_dz = 0.5 / nz\n",
    "n_voxels = nx * ny * nz\n",
    "\n",
    "X2 = torch.zeros(X.shape)\n",
    "Y2 = torch.zeros(Y.shape)\n",
    "n=0\n",
    "for i in range(nx):\n",
    "  for j in range(ny):\n",
    "    for k in range(nz):\n",
    "      X2[n,0] = (i * 1.0 / nx)\n",
    "      X2[n,1] = (j * 1.0 / ny)\n",
    "      X2[n,2] = (k * 1.0 / nz)\n",
    "      Y2[n,0] = data[i,j,k]\n",
    "      n = n+1\n",
    "Y2 = (Y2 - torch.min(Y2)) / (torch.max(Y2) - torch.min(Y2)) * 2 - 1\n",
    "\n",
    "#Check ordering\n",
    "nonz = np.argwhere(Y>0)\n",
    "print(nonz.shape)\n",
    "elm = nonz[0,0]\n",
    "print(X[elm:elm+3,:])\n",
    "print(X2[elm:elm+3,:])\n",
    "print(Y[elm:elm+3,:])\n",
    "print(Y2[elm:elm+3,:])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "n_levels = 6\n",
    "n_features_per_level = 2\n",
    "n_features = n_levels * n_features_per_level\n",
    "base_resolution = 32#16\n",
    "b = np.exp((np.log(nmax)-np.log(base_resolution))/(n_levels-1))\n",
    "print(b)\n",
    "\n",
    "#https://github.com/NVlabs/tiny-cuda-nn/blob/master/DOCUMENTATION.md\n",
    "config = {\n",
    "\"encoding\": {\n",
    "    \"otype\": \"HashGrid\",\n",
    "    \"n_levels\": n_levels,\n",
    "    \"n_features_per_level\": n_features_per_level,\n",
    "    \"log2_hashmap_size\": 19,\n",
    "    \"base_resolution\": base_resolution,\n",
    "    \"per_level_scale\": b#1.3819#1.5\n",
    "},\n",
    "\"network\": {\n",
    "    \"otype\": \"FullyFusedMLP\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"output_activation\": \"None\",\n",
    "    \"n_neurons\": 128,\n",
    "    \"n_hidden_layers\": 2\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HashMLP(config = config, dim_in=3, dim_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "#trainer = pl.Trainer(gpus=1,max_epochs=num_epochs, precision=16) # provides the gpu if necessary\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, precision=16) # no need to provide the gpu (depends on GPU type?)\n",
    "trainer.fit(net, loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X = X.to(device='cuda')\n",
    "net = net.to(device='cuda')\n",
    "enc = net.encoding(X)\n",
    "recon = net.forward(X)\n",
    "print(enc.shape)\n",
    "print(mgrid.shape)\n",
    "print(data.shape)\n",
    "print(recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4d = enc.cpu().detach().numpy().reshape((nx,ny,nz,n_features))\n",
    "nib.save(nib.Nifti1Image(np.float32(data4d),image.affine), os.path.join(home,'enc.nii.gz'))\n",
    "\n",
    "data3d = recon.cpu().detach().numpy().reshape((nx,ny,nz,1))\n",
    "nib.save(nib.Nifti1Image(np.float32(data3d),image.affine),os.path.join(home,'recon.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf1 = int(n_features / 3)\n",
    "nf2 = int(n_features * 2 / 3)\n",
    "print(nf1)\n",
    "print(nf2)\n",
    "\n",
    "enc_low = torch.zeros(enc.shape)\n",
    "enc_low[:,0:nf1] = enc[:,0:nf1]\n",
    "recon_low = net.mlp(enc_low)\n",
    "data_low = recon_low.cpu().detach().numpy().reshape((nx,ny,nz,1))\n",
    "nib.save(nib.Nifti1Image(np.float32(data_low),image.affine),os.path.join(home,'recon_low.nii.gz'))\n",
    "\n",
    "enc_med = torch.zeros(enc.shape)\n",
    "enc_med[:,nf1:nf2] = enc[:,nf1:nf2]\n",
    "recon_med = net.mlp(enc_med)\n",
    "data_med = recon_med.cpu().detach().numpy().reshape((nx,ny,nz,1))\n",
    "nib.save(nib.Nifti1Image(np.float32(data_med),image.affine),os.path.join(home,'recon_med.nii.gz'))\n",
    "\n",
    "enc_high = torch.zeros(enc.shape)\n",
    "enc_high[:,nf2:n_features] = enc[:,nf2:n_features]\n",
    "recon_high = net.mlp(enc_high)\n",
    "data_high = recon_high.cpu().detach().numpy().reshape((nx,ny,nz,1))\n",
    "nib.save(nib.Nifti1Image(np.float32(data_high),image.affine),os.path.join(home,'recon_high.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
